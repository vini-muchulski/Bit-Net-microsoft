# -*- coding: utf-8 -*-
"""Bit Net microsoft

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T7k0NVFZrFFhaRcnsiSAQxjd86n1Lzc0

# Bit Net

- Docs : https://github.com/microsoft/BitNet

- Source : https://huggingface.co/microsoft/bitnet-b1.58-2B-4T-gguf
"""

# Commented out IPython magic to ensure Python compatibility.
!git clone --recursive https://github.com/microsoft/BitNet.git
# %cd BitNet

""" - these process may take a long"""

!pip install -r requirements.txt -q

"""- Download the weights"""

!huggingface-cli download microsoft/BitNet-b1.58-2B-4T-gguf --local-dir models/BitNet-b1.58-2B-4T

"""- Set the initial environment - may take a long"""

!python setup_env.py -md models/BitNet-b1.58-2B-4T -q i2_s

"""- Basic usage
- Run inference with the quantized model
"""

!python run_inference.py -m models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf -p "You are a helpful assistant" -cnv