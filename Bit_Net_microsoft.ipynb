{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Bit Net"
      ],
      "metadata": {
        "id": "S0NNMmjQCSay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- Docs : https://github.com/microsoft/BitNet\n",
        "\n",
        "- Source : https://huggingface.co/microsoft/bitnet-b1.58-2B-4T-gguf"
      ],
      "metadata": {
        "id": "ox2hxZzugy62"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Hchwh8rfxQy",
        "outputId": "bc444265-583b-4573-bbfa-f681ed7a4ac4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'BitNet'...\n",
            "remote: Enumerating objects: 255, done.\u001b[K\n",
            "remote: Counting objects: 100% (161/161), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 255 (delta 117), reused 75 (delta 75), pack-reused 94 (from 3)\u001b[K\n",
            "Receiving objects: 100% (255/255), 2.04 MiB | 11.10 MiB/s, done.\n",
            "Resolving deltas: 100% (125/125), done.\n",
            "Submodule '3rdparty/llama.cpp' (https://github.com/Eddie-Wang1120/llama.cpp.git) registered for path '3rdparty/llama.cpp'\n",
            "Cloning into '/content/BitNet/3rdparty/llama.cpp'...\n",
            "remote: Enumerating objects: 25611, done.        \n",
            "remote: Total 25611 (delta 0), reused 0 (delta 0), pack-reused 25611 (from 1)        \n",
            "Receiving objects: 100% (25611/25611), 59.25 MiB | 9.44 MiB/s, done.\n",
            "Resolving deltas: 100% (18272/18272), done.\n",
            "Submodule path '3rdparty/llama.cpp': checked out 'a8ac7072ae02ffd68b4b661db0ebd2689fb82b7f'\n",
            "Submodule 'kompute' (https://github.com/nomic-ai/kompute.git) registered for path '3rdparty/llama.cpp/ggml/src/kompute'\n",
            "Cloning into '/content/BitNet/3rdparty/llama.cpp/ggml/src/kompute'...\n",
            "remote: Enumerating objects: 9122, done.        \n",
            "remote: Counting objects: 100% (155/155), done.        \n",
            "remote: Compressing objects: 100% (69/69), done.        \n",
            "remote: Total 9122 (delta 109), reused 86 (delta 86), pack-reused 8967 (from 3)        \n",
            "Receiving objects: 100% (9122/9122), 17.59 MiB | 23.85 MiB/s, done.\n",
            "Resolving deltas: 100% (5728/5728), done.\n",
            "Submodule path '3rdparty/llama.cpp/ggml/src/kompute': checked out '4565194ed7c32d1d2efa32ceab4d3c6cae006306'\n",
            "/content/BitNet\n"
          ]
        }
      ],
      "source": [
        "!git clone --recursive https://github.com/microsoft/BitNet.git\n",
        "%cd BitNet"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " - these process may take a long"
      ],
      "metadata": {
        "id": "qgu2rT8PDRCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH6rpf6Af3zb",
        "outputId": "43649db0-2a4d-48e0-98cd-005026c0ed9e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.8/186.8 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.6 which is incompatible.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.2.2+cpu which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.2.2+cpu which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Download the weights"
      ],
      "metadata": {
        "id": "k99kc-96CiX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli download microsoft/BitNet-b1.58-2B-4T-gguf --local-dir models/BitNet-b1.58-2B-4T\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Lmj5ZE4f5QI",
        "outputId": "a58f4225-a665-4cbf-af5a-f441e8feb514"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching 3 files:   0% 0/3 [00:00<?, ?it/s]Downloading 'ggml-model-i2_s.gguf' to 'models/BitNet-b1.58-2B-4T/.cache/huggingface/download/f28pn7v36EcygdlMWvHpzrkkz6A=.13939ce5030319a35db346e5dba7a3a3bd599dfc18b113a2a97446ff964714c5.incomplete'\n",
            "\n",
            "ggml-model-i2_s.gguf:   0% 0.00/1.84G [00:00<?, ?B/s]\u001b[ADownloading 'README.md' to 'models/BitNet-b1.58-2B-4T/.cache/huggingface/download/Xn7B-BWUGOee2Y6hCZtEhtFu4BE=.c4a6897e03fbb0320ded5e0b686d8a5e1968154c.incomplete'\n",
            "\n",
            "ggml-model-i2_s.gguf:   1% 21.0M/1.84G [00:00<00:11, 155MB/s]\u001b[A\n",
            "\n",
            "README.md: 100% 8.96k/8.96k [00:00<00:00, 20.7MB/s]\n",
            "Download complete. Moving file to models/BitNet-b1.58-2B-4T/README.md\n",
            "\n",
            "ggml-model-i2_s.gguf:   3% 52.4M/1.84G [00:00<00:08, 223MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:   5% 83.9M/1.84G [00:00<00:06, 255MB/s]\u001b[ADownloading '.gitattributes' to 'models/BitNet-b1.58-2B-4T/.cache/huggingface/download/wPaCkH-WbT7GsmxMKKrNZTV4nSM=.4e3e1a539c8d36087c5f8435e653b7dc694a0da6.incomplete'\n",
            "\n",
            "\n",
            ".gitattributes: 100% 1.64k/1.64k [00:00<00:00, 6.81MB/s]\n",
            "Download complete. Moving file to models/BitNet-b1.58-2B-4T/.gitattributes\n",
            "Fetching 3 files:  33% 1/3 [00:00<00:01,  1.74it/s]\n",
            "ggml-model-i2_s.gguf:   6% 115M/1.84G [00:00<00:06, 255MB/s] \u001b[A\n",
            "ggml-model-i2_s.gguf:   8% 147M/1.84G [00:00<00:07, 240MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  10% 178M/1.84G [00:00<00:06, 251MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  11% 210M/1.84G [00:00<00:06, 257MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  13% 241M/1.84G [00:00<00:06, 261MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  15% 273M/1.84G [00:01<00:05, 263MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  16% 304M/1.84G [00:01<00:05, 262MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  18% 336M/1.84G [00:01<00:05, 263MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  20% 367M/1.84G [00:01<00:05, 268MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  22% 398M/1.84G [00:01<00:05, 268MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  23% 430M/1.84G [00:01<00:05, 264MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  25% 461M/1.84G [00:01<00:05, 264MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  27% 493M/1.84G [00:01<00:05, 267MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  28% 524M/1.84G [00:02<00:04, 269MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  30% 556M/1.84G [00:02<00:04, 270MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  32% 587M/1.84G [00:02<00:04, 273MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  34% 619M/1.84G [00:02<00:04, 271MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  35% 650M/1.84G [00:02<00:04, 249MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  37% 682M/1.84G [00:02<00:04, 235MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  39% 713M/1.84G [00:02<00:04, 229MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  40% 744M/1.84G [00:02<00:04, 231MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  42% 776M/1.84G [00:03<00:04, 219MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  44% 807M/1.84G [00:03<00:04, 224MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  45% 839M/1.84G [00:03<00:04, 216MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  47% 870M/1.84G [00:03<00:04, 211MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  49% 902M/1.84G [00:03<00:04, 204MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  50% 923M/1.84G [00:03<00:04, 200MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  51% 944M/1.84G [00:04<00:09, 97.5MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  53% 975M/1.84G [00:04<00:07, 119MB/s] \u001b[A\n",
            "ggml-model-i2_s.gguf:  54% 996M/1.84G [00:04<00:06, 130MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  56% 1.03G/1.84G [00:04<00:05, 151MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  57% 1.06G/1.84G [00:04<00:04, 168MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  59% 1.08G/1.84G [00:05<00:04, 176MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  60% 1.11G/1.84G [00:05<00:03, 184MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  62% 1.14G/1.84G [00:05<00:03, 190MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  63% 1.16G/1.84G [00:05<00:03, 192MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  65% 1.20G/1.84G [00:05<00:03, 211MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  67% 1.23G/1.84G [00:05<00:02, 223MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  68% 1.26G/1.84G [00:05<00:02, 230MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  70% 1.29G/1.84G [00:05<00:02, 228MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  72% 1.32G/1.84G [00:06<00:02, 240MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  73% 1.35G/1.84G [00:06<00:01, 247MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  75% 1.38G/1.84G [00:06<00:01, 247MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  77% 1.42G/1.84G [00:06<00:01, 253MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  78% 1.45G/1.84G [00:06<00:01, 251MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  80% 1.48G/1.84G [00:06<00:01, 255MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  82% 1.51G/1.84G [00:06<00:01, 249MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  84% 1.54G/1.84G [00:06<00:01, 244MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  85% 1.57G/1.84G [00:07<00:01, 252MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  87% 1.60G/1.84G [00:07<00:00, 258MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  89% 1.64G/1.84G [00:07<00:00, 256MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  90% 1.67G/1.84G [00:07<00:00, 257MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  92% 1.70G/1.84G [00:07<00:00, 258MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  94% 1.73G/1.84G [00:07<00:00, 251MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  96% 1.76G/1.84G [00:07<00:00, 250MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf:  97% 1.79G/1.84G [00:07<00:00, 254MB/s]\u001b[A\n",
            "ggml-model-i2_s.gguf: 100% 1.84G/1.84G [00:08<00:00, 226MB/s]\n",
            "Download complete. Moving file to models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf\n",
            "Fetching 3 files: 100% 3/3 [00:08<00:00,  2.77s/it]\n",
            "/content/BitNet/models/BitNet-b1.58-2B-4T\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Set the initial environment - may take a long"
      ],
      "metadata": {
        "id": "HQmG7Ec6Cq2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python setup_env.py -md models/BitNet-b1.58-2B-4T -q i2_s\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pHM5FkJf_ZP",
        "outputId": "ef047e76-5786-4284-9277-bfc08a970fd1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:root:Compiling the code using CMake.\n",
            "INFO:root:Loading model from directory models/BitNet-b1.58-2B-4T.\n",
            "INFO:root:GGUF model already exists at models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Basic usage\n",
        "- Run inference with the quantized model"
      ],
      "metadata": {
        "id": "Xx09X1M4Czlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_inference.py -m models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf -p \"You are a helpful assistant\" -cnv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLJyxNeVgCM6",
        "outputId": "918acd7b-20b1-4bce-a80b-4e7e5608f540"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "warning: not compiled with GPU offload support, --gpu-layers option will be ignored\n",
            "warning: see main README.md for information on enabling GPU BLAS support\n",
            "build: 3955 (a8ac7072) with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: llama backend init\n",
            "main: load the model and apply lora adapter, if any\n",
            "llama_model_loader: loaded meta data with 24 key-value pairs and 333 tensors from models/BitNet-b1.58-2B-4T/ggml-model-i2_s.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = bitnet-25\n",
            "llama_model_loader: - kv   1:                               general.name str              = bitnet2b_2501\n",
            "llama_model_loader: - kv   2:                       bitnet-25.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv   3:                   bitnet-25.context_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                 bitnet-25.embedding_length u32              = 2560\n",
            "llama_model_loader: - kv   5:                      bitnet-25.block_count u32              = 30\n",
            "llama_model_loader: - kv   6:              bitnet-25.feed_forward_length u32              = 6912\n",
            "llama_model_loader: - kv   7:             bitnet-25.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   8:             bitnet-25.attention.head_count u32              = 20\n",
            "llama_model_loader: - kv   9:          bitnet-25.attention.head_count_kv u32              = 5\n",
            "llama_model_loader: - kv  10:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  11: bitnet-25.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  12:                   bitnet-25.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  13:                          general.file_type u32              = 40\n",
            "llama_model_loader: - kv  14:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  16:                      tokenizer.ggml.scores arr[f32,128256]  = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  18:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  19:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  20:                tokenizer.ggml.eos_token_id u32              = 128001\n",
            "llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 128001\n",
            "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {% for message in messages %}{% if lo...\n",
            "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:  121 tensors\n",
            "llama_model_loader: - type  f16:    2 tensors\n",
            "llama_model_loader: - type i2_s:  210 tensors\n",
            "llm_load_vocab: missing pre-tokenizer type, using: 'default'\n",
            "llm_load_vocab:                                             \n",
            "llm_load_vocab: ************************************        \n",
            "llm_load_vocab: GENERATION QUALITY WILL BE DEGRADED!        \n",
            "llm_load_vocab: CONSIDER REGENERATING THE MODEL             \n",
            "llm_load_vocab: ************************************        \n",
            "llm_load_vocab:                                             \n",
            "llm_load_vocab: control token: 128255 '<|reserved_special_token_250|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128254 '<|reserved_special_token_249|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128253 '<|reserved_special_token_248|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128251 '<|reserved_special_token_246|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128246 '<|reserved_special_token_241|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128243 '<|reserved_special_token_238|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128240 '<|reserved_special_token_235|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128239 '<|reserved_special_token_234|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128238 '<|reserved_special_token_233|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128237 '<|reserved_special_token_232|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128232 '<|reserved_special_token_227|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128228 '<|reserved_special_token_223|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128227 '<|reserved_special_token_222|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128225 '<|reserved_special_token_220|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128222 '<|reserved_special_token_217|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128215 '<|reserved_special_token_210|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128211 '<|reserved_special_token_206|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128210 '<|reserved_special_token_205|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128204 '<|reserved_special_token_199|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128203 '<|reserved_special_token_198|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128201 '<|reserved_special_token_196|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128197 '<|reserved_special_token_192|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128196 '<|reserved_special_token_191|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128195 '<|reserved_special_token_190|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128193 '<|reserved_special_token_188|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128191 '<|reserved_special_token_186|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128190 '<|reserved_special_token_185|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128185 '<|reserved_special_token_180|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128184 '<|reserved_special_token_179|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128182 '<|reserved_special_token_177|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128181 '<|reserved_special_token_176|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128177 '<|reserved_special_token_172|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128176 '<|reserved_special_token_171|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128175 '<|reserved_special_token_170|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128174 '<|reserved_special_token_169|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128173 '<|reserved_special_token_168|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128172 '<|reserved_special_token_167|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128168 '<|reserved_special_token_163|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128167 '<|reserved_special_token_162|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128166 '<|reserved_special_token_161|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128165 '<|reserved_special_token_160|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128162 '<|reserved_special_token_157|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128159 '<|reserved_special_token_154|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128155 '<|reserved_special_token_150|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128153 '<|reserved_special_token_148|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128152 '<|reserved_special_token_147|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128151 '<|reserved_special_token_146|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128148 '<|reserved_special_token_143|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128146 '<|reserved_special_token_141|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128144 '<|reserved_special_token_139|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128143 '<|reserved_special_token_138|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128141 '<|reserved_special_token_136|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128139 '<|reserved_special_token_134|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128138 '<|reserved_special_token_133|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128135 '<|reserved_special_token_130|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128133 '<|reserved_special_token_128|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128132 '<|reserved_special_token_127|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128131 '<|reserved_special_token_126|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128130 '<|reserved_special_token_125|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128128 '<|reserved_special_token_123|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128125 '<|reserved_special_token_120|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128121 '<|reserved_special_token_116|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128120 '<|reserved_special_token_115|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128119 '<|reserved_special_token_114|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128116 '<|reserved_special_token_111|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128112 '<|reserved_special_token_107|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128109 '<|reserved_special_token_104|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128107 '<|reserved_special_token_102|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128106 '<|reserved_special_token_101|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128105 '<|reserved_special_token_100|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128103 '<|reserved_special_token_98|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128100 '<|reserved_special_token_95|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128099 '<|reserved_special_token_94|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128098 '<|reserved_special_token_93|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128094 '<|reserved_special_token_89|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128088 '<|reserved_special_token_83|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128087 '<|reserved_special_token_82|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128086 '<|reserved_special_token_81|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128084 '<|reserved_special_token_79|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128082 '<|reserved_special_token_77|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128078 '<|reserved_special_token_73|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128075 '<|reserved_special_token_70|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128073 '<|reserved_special_token_68|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128072 '<|reserved_special_token_67|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128070 '<|reserved_special_token_65|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128065 '<|reserved_special_token_60|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128064 '<|reserved_special_token_59|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128062 '<|reserved_special_token_57|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128060 '<|reserved_special_token_55|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128059 '<|reserved_special_token_54|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128057 '<|reserved_special_token_52|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128056 '<|reserved_special_token_51|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128054 '<|reserved_special_token_49|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128051 '<|reserved_special_token_46|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128043 '<|reserved_special_token_38|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128042 '<|reserved_special_token_37|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128041 '<|reserved_special_token_36|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128040 '<|reserved_special_token_35|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128035 '<|reserved_special_token_30|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128033 '<|reserved_special_token_28|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128032 '<|reserved_special_token_27|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128029 '<|reserved_special_token_24|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128025 '<|reserved_special_token_20|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128024 '<|reserved_special_token_19|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128021 '<|reserved_special_token_16|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128020 '<|reserved_special_token_15|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128019 '<|reserved_special_token_14|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128018 '<|reserved_special_token_13|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128015 '<|reserved_special_token_10|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128013 '<|reserved_special_token_8|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128012 '<|reserved_special_token_7|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128010 '<|reserved_special_token_5|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128005 '<|reserved_special_token_3|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128004 '<|reserved_special_token_2|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128002 '<|reserved_special_token_0|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128249 '<|reserved_special_token_244|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128187 '<|reserved_special_token_182|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128180 '<|reserved_special_token_175|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128134 '<|reserved_special_token_129|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128179 '<|reserved_special_token_174|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128037 '<|reserved_special_token_32|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128045 '<|reserved_special_token_40|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128089 '<|reserved_special_token_84|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128212 '<|reserved_special_token_207|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128104 '<|reserved_special_token_99|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128205 '<|reserved_special_token_200|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128142 '<|reserved_special_token_137|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128028 '<|reserved_special_token_23|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128126 '<|reserved_special_token_121|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128198 '<|reserved_special_token_193|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128071 '<|reserved_special_token_66|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128092 '<|reserved_special_token_87|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128183 '<|reserved_special_token_178|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128140 '<|reserved_special_token_135|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128226 '<|reserved_special_token_221|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128007 '<|end_header_id|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128052 '<|reserved_special_token_47|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128053 '<|reserved_special_token_48|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128058 '<|reserved_special_token_53|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128150 '<|reserved_special_token_145|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128149 '<|reserved_special_token_144|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128209 '<|reserved_special_token_204|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128169 '<|reserved_special_token_164|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128157 '<|reserved_special_token_152|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128038 '<|reserved_special_token_33|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128178 '<|reserved_special_token_173|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128091 '<|reserved_special_token_86|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128115 '<|reserved_special_token_110|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128233 '<|reserved_special_token_228|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128145 '<|reserved_special_token_140|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128039 '<|reserved_special_token_34|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128136 '<|reserved_special_token_131|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128170 '<|reserved_special_token_165|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128236 '<|reserved_special_token_231|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128154 '<|reserved_special_token_149|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128049 '<|reserved_special_token_44|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128023 '<|reserved_special_token_18|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128003 '<|reserved_special_token_1|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128016 '<|reserved_special_token_11|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128113 '<|reserved_special_token_108|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128158 '<|reserved_special_token_153|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128223 '<|reserved_special_token_218|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128156 '<|reserved_special_token_151|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128008 '<|reserved_special_token_4|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128085 '<|reserved_special_token_80|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128160 '<|reserved_special_token_155|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128001 '<|end_of_text|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128110 '<|reserved_special_token_105|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128247 '<|reserved_special_token_242|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128122 '<|reserved_special_token_117|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128050 '<|reserved_special_token_45|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128221 '<|reserved_special_token_216|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128244 '<|reserved_special_token_239|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128248 '<|reserved_special_token_243|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128213 '<|reserved_special_token_208|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128006 '<|start_header_id|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128208 '<|reserved_special_token_203|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128074 '<|reserved_special_token_69|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128234 '<|reserved_special_token_229|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128083 '<|reserved_special_token_78|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128224 '<|reserved_special_token_219|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128055 '<|reserved_special_token_50|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128097 '<|reserved_special_token_92|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128206 '<|reserved_special_token_201|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128081 '<|reserved_special_token_76|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128068 '<|reserved_special_token_63|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128067 '<|reserved_special_token_62|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128046 '<|reserved_special_token_41|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128194 '<|reserved_special_token_189|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128069 '<|reserved_special_token_64|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128000 '<|begin_of_text|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128220 '<|reserved_special_token_215|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128214 '<|reserved_special_token_209|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128108 '<|reserved_special_token_103|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128200 '<|reserved_special_token_195|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128048 '<|reserved_special_token_43|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128027 '<|reserved_special_token_22|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128114 '<|reserved_special_token_109|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128235 '<|reserved_special_token_230|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128252 '<|reserved_special_token_247|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128199 '<|reserved_special_token_194|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128129 '<|reserved_special_token_124|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128245 '<|reserved_special_token_240|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128164 '<|reserved_special_token_159|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128124 '<|reserved_special_token_119|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128102 '<|reserved_special_token_97|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128036 '<|reserved_special_token_31|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128229 '<|reserved_special_token_224|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128163 '<|reserved_special_token_158|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128127 '<|reserved_special_token_122|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128111 '<|reserved_special_token_106|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128231 '<|reserved_special_token_226|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128188 '<|reserved_special_token_183|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128061 '<|reserved_special_token_56|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128137 '<|reserved_special_token_132|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128093 '<|reserved_special_token_88|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128095 '<|reserved_special_token_90|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128189 '<|reserved_special_token_184|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128090 '<|reserved_special_token_85|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128147 '<|reserved_special_token_142|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128219 '<|reserved_special_token_214|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128230 '<|reserved_special_token_225|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128217 '<|reserved_special_token_212|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128031 '<|reserved_special_token_26|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128030 '<|reserved_special_token_25|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128250 '<|reserved_special_token_245|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128192 '<|reserved_special_token_187|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128096 '<|reserved_special_token_91|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128186 '<|reserved_special_token_181|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128207 '<|reserved_special_token_202|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128171 '<|reserved_special_token_166|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128080 '<|reserved_special_token_75|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128077 '<|reserved_special_token_72|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128101 '<|reserved_special_token_96|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128079 '<|reserved_special_token_74|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128216 '<|reserved_special_token_211|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128014 '<|reserved_special_token_9|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128047 '<|reserved_special_token_42|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128202 '<|reserved_special_token_197|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128044 '<|reserved_special_token_39|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128161 '<|reserved_special_token_156|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128017 '<|reserved_special_token_12|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128066 '<|reserved_special_token_61|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128242 '<|reserved_special_token_237|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128118 '<|reserved_special_token_113|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128076 '<|reserved_special_token_71|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128034 '<|reserved_special_token_29|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128241 '<|reserved_special_token_236|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128026 '<|reserved_special_token_21|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128218 '<|reserved_special_token_213|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128063 '<|reserved_special_token_58|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128117 '<|reserved_special_token_112|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128011 '<|reserved_special_token_6|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128022 '<|reserved_special_token_17|>' is not marked as EOG\n",
            "llm_load_vocab: control token: 128123 '<|reserved_special_token_118|>' is not marked as EOG\n",
            "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "llm_load_vocab: special tokens cache size = 256\n",
            "llm_load_vocab: token to piece cache size = 0.8000 MB\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = bitnet-25\n",
            "llm_load_print_meta: vocab type       = BPE\n",
            "llm_load_print_meta: n_vocab          = 128256\n",
            "llm_load_print_meta: n_merges         = 280147\n",
            "llm_load_print_meta: vocab_only       = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 2560\n",
            "llm_load_print_meta: n_layer          = 30\n",
            "llm_load_print_meta: n_head           = 20\n",
            "llm_load_print_meta: n_head_kv        = 5\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_swa            = 0\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 640\n",
            "llm_load_print_meta: n_embd_v_gqa     = 640\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 6912\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 2\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 500000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_ctx_orig_yarn  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
            "llm_load_print_meta: model type       = 2B\n",
            "llm_load_print_meta: model ftype      = I2_S - 2 bpw ternary\n",
            "llm_load_print_meta: model params     = 2.74 B\n",
            "llm_load_print_meta: model size       = 1.71 GiB (5.36 BPW) \n",
            "llm_load_print_meta: general.name     = bitnet2b_2501\n",
            "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
            "llm_load_print_meta: EOS token        = 128001 '<|end_of_text|>'\n",
            "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
            "llm_load_print_meta: PAD token        = 128001 '<|end_of_text|>'\n",
            "llm_load_print_meta: LF token         = 128 'Ä'\n",
            "llm_load_print_meta: EOG token        = 128001 '<|end_of_text|>'\n",
            "llm_load_print_meta: EOG token        = 128009 '<|eot_id|>'\n",
            "llm_load_print_meta: max token length = 256\n",
            "llm_load_tensors: ggml ctx size =    0.15 MiB\n",
            "llm_load_tensors:        CPU buffer size =  1751.06 MiB\n",
            "...............................\n",
            "llama_new_context_with_model: n_batch is less than GGML_KQ_MASK_PAD - increasing to 32\n",
            "llama_new_context_with_model: n_ctx      = 2048\n",
            "llama_new_context_with_model: n_batch    = 32\n",
            "llama_new_context_with_model: n_ubatch   = 32\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 500000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =   150.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  150.00 MiB, K (f16):   75.00 MiB, V (f16):   75.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.49 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =    15.97 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1116\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "common_init_from_params: warming up the model with an empty run - please wait ... (--no-warmup to disable)\n",
            "main: llama threadpool init, n_threads = 2\n",
            "main: chat template example:\n",
            "System: You are a helpful assistantUser: Hello<|eot_id|>Assistant: Hi thereUser: How are you?<|eot_id|>Assistant: \n",
            "\n",
            "system_info: n_threads = 2 (n_threads_batch = 2) / 2 | AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "\n",
            "main: interactive mode on.\n",
            "sampler seed: 3552288290\n",
            "sampler params: \n",
            "\trepeat_last_n = 64, repeat_penalty = 1.000, frequency_penalty = 0.000, presence_penalty = 0.000\n",
            "\ttop_k = 40, tfs_z = 1.000, top_p = 0.950, min_p = 0.050, typical_p = 1.000, temp = 0.800\n",
            "\tmirostat = 0, mirostat_lr = 0.100, mirostat_ent = 5.000\n",
            "sampler chain: logits -> logit-bias -> penalties -> top-k -> tail-free -> typical -> top-p -> min-p -> temp-ext -> softmax -> dist \n",
            "generate: n_ctx = 2048, n_batch = 1, n_predict = 128, n_keep = 1\n",
            "\n",
            "== Running in interactive mode. ==\n",
            " - Press Ctrl+C to interject at any time.\n",
            " - Press Return to return control to the AI.\n",
            " - To return control without starting a new line, end your input with '/'.\n",
            " - If you want to submit another line, end your input with '\\'.\n",
            "\n",
            "System: You are a helpful assistant\n",
            "> what was the apollo 11\n",
            "The Apollo 11 was the second mission of NASA's Apollo space program, which was the United States' manned spaceflight program and the U.S. government's project to land humans on the Moon and return them safely to Earth. The mission was the first crewed mission to land on the Moon since the Soviet Union's Voskhod mission in 1962.\n",
            "\n",
            "The Apollo 11 mission took place on July 20, 1969. It was commanded by Neil Armstrong, with Michael Collins in the Command Module (CM) and Edwin \"Buzz\" Aldrin\n",
            "> Ctrl+C pressed, exiting...\n",
            "Ctrl+C pressed, exiting...\n"
          ]
        }
      ]
    }
  ]
}